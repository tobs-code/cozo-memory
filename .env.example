# Embedding Model Configuration
# Choose one of the following models:
# 
# AUTOMATIC DOWNLOAD (Xenova models):
# - Xenova/bge-m3 (1024 dimensions, ~600MB, multilingual, 8K context) [DEFAULT]
# - Xenova/nomic-embed-text-v1 (768 dimensions, ~200MB, English-only, 8K context)
# - Xenova/bge-small-en-v1.5 (384 dimensions, ~130MB, English-only, balanced)
# - Xenova/all-MiniLM-L6-v2 (384 dimensions, ~80MB, fastest, lower RAM)
#
# MANUAL DOWNLOAD REQUIRED (Non-Xenova models):
# - perplexity-ai/pplx-embed-v1-0.6b (1024 dimensions, ~2.4GB ONNX, multilingual, 32K context, SOTA)
#   Download: npm run download-pplx-embed
#   See PPLX_EMBED_INTEGRATION.md for manual download instructions

EMBEDDING_MODEL=Xenova/bge-m3

# Ollama Integration (alternative to ONNX)
# Set USE_OLLAMA=true to use Ollama instead of ONNX models
# This is useful for testing models like pplx-embed that have tokenizer issues with ONNX
# USE_OLLAMA=true
# OLLAMA_EMBEDDING_MODEL=argus-ai/pplx-embed-v1-0.6b:q8_0
# OLLAMA_BASE_URL=http://localhost:11434

# Database Configuration (optional)
# DB_ENGINE=sqlite  # or 'rocksdb' for high-performance

# API Bridge Configuration (optional)
# PORT=3001
